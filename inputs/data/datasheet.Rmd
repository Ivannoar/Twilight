---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: https://github.com/Ivannoar/Twilight."
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
output:
  bookdown::pdf_document2
toc: FALSE
bibliography: references_datasheet.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Extract of the questions from @gebru2021datasheets


**Motivation**

1. *For what purpose was the dataset created? Was there a specific task in mind? Was there a specific gap that needed to be filled? Please provide a description.*
    - The dataset was created to conduct analysis on Twitter trends regarding the popular online game Wordle. Twitter is a convenient website to gather large amounts of player statistics as users regularily and daily share their scores in an easy to analyze format.
2. *Who created the dataset (for example, which team, research group) and on behalf of which entity (for example, company, institution, organization)?*
    - The dataset was created by the author of this paper to serve the paper's purposes.
3. *Who funded the creation of the dataset? If there is an associated grant, please provide the name of the grantor and the grant name and number.*
    - No monetary cost was required in the creation of the dataset; it was created free of cost using the rtweet [@citertweet] package and the programming software R [@citeR].
4. *Any other comments?*
    - Due to data gathering errors, there is a gap in the temporal data of the dataset. A large majority of the tweets are gathered at a general timepoint correlating to when the tweets were obtained. As such, the tweets are not evenly distributed timewise.

**Composition**

1. *What do the instances that comprise the dataset represent (for example, documents, photos, people, countries)? Are there multiple types of instances (for example, movies, users, and ratings; people and interactions between them; nodes and edges)? Please provide a description.*
	- Each instance of an observation represents a message known as a 'tweet'. This message is akin to a text message which may contain emoticons, pictures, and GIFs attached with the message. Tweets can also be sent as replies to other tweets, or as a quote tweet which is standalone but is connected to an initial message.
2. *How many instances are there in total (of each type, if appropriate)?*
	- In total, there are 508000 instances and 508000 gathered tweets.
3. *Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set? If the dataset is a sample, then what is the larger set? Is the sample representative of the larger set (for example, geographic coverage)? If so, please describe how this representativeness was validated/verified. If it is not representative of the larger set, please describe why not (for example, to cover a more diverse range of instances, because instances were withheld or unavailable).*
	- The dataset does not contain all possible instances. Billions of messages are sent and processed by Twitter daily and it is impossible to process and filter such a colossal stream of data to obtain only relevant data. The dataset is a sample of tweets relevant to Wordle and the larger set would consist of all relevant tweets made each day for the period of data gathering. The sample is not chronologically representative of the entire set because of limitations with data gathering. rtweet is limited in that it can only gather 'recent' tweets related to when the request is sent. Due to this, evenly distributed chronological coverage was not able to be gathered. 
4. *What data does each instance consist of? "Raw" data (for example, unprocessed text or images) or features? In either case, please provide a description.*
	- Each instance consists of a message sent in text and unicode characters, which may have a picture or GIF attached. There are also properties of the tweet and sender account such as chronological data in the dataset.
5. *Is there a label or target associated with each instance? If so, please provide a description.*
	- Each tweet has a status id which is shown in the raw data. This status id is unique and directly corresponds to the pertaining message in the Twitter databse. 
6. *Is any information missing from individual instances? If so, please provide a description, explaining why this information is missing (for example, because it was unavailable). This does not include intentionally removed information, but might include, for example, redacted text.*
	- There is no information missing that was blocked by Twitter or our data collecting programs. Information such as the location of the sender of the tweet or the account information may be intentionally withheld due to privacy concerns of the user.  
7. *Are relationships between individual instances made explicit (for example, users' movie ratings, social network links)? If so, please describe how these relationships are made explicit.*
	- Relationships between invididual instances are made explicit. Part of the raw data contains information about if the instance was a reply or 'quote tweet' in response to an initial tweet. These initial tweets may or may not be in the dataset, and this can be verified by using the status id of the initial message and checking if it is in the dataset.
8. *Are there recommended data splits (for example, training, development/validation, testing)? If so, please provide a description of these splits, explaining the rationale behind them.*
	- A datasplit of 80/20 for the training and testing datasets will be used to create and test models for the data. These splits will consist of randomly sampled partitions of the data and will be done so to mitigate bias from the models created.
9. *Are there any errors, sources of noise, or redundancies in the dataset? If so, please provide a description.*
	- Some sources of noise may include tweets which matched our criteria for relevance and were obtained but do not provide any usable information. There may also be 'joke' results which parody the data we wish to obtain but is itself not accurate information. 
10. *Is the dataset self-contained, or does it link to or otherwise rely on external resources (for example, websites, tweets, other datasets)? If it links to or relies on external resources, a) are there guarantees that they will exist, and remain constant, over time; b) are there official archival versions of the complete dataset (that is, including the external resources as they existed at the time the dataset was created); c) are there any restrictions (for example, licenses, fees) associated with any of the external resources that might apply to a dataset consumer? Please provide descriptions of all external resources and any restrictions associated with them, as well as links or other access points, as appropriate.*
	- The dataset relies on external resources, as we are looking at tweets. There are no guarantees that they will exist in the future as Twitter and its users have the right to delete and hide tweets at any moment. However, archival services exist which would allow for the messages to be preserved. As well, deleted tweets are stored in Twitter's databases, although unavailible to the public.
11. *Does the dataset contain data that might be considered confidential (for example, data that is protected by legal privilege or by doctor-patient confidentiality, data that includes the content of individuals' non-public communications)? If so, please provide a description.*
	- The dataset may contain confidential data if the user explicitly and voluntarily mentioned this in their tweet. 
12. *Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? If so, please describe why.*
	- The dataset may contain offensive, insulting, and malicious text if the user chose to include such text in their original tweet.
13. *Does the dataset identify any sub-populations (for example, by age, gender)? If so, please describe how these subpopulations are identified and provide a description of their respective distributions within the dataset.*
	- The dataset does not identify any sub-populations as this data is not obtainible from tweets.
14. *Is it possible to identify individuals (that is, one or more natural persons), either directly or indirectly (that is, in combination with other data) from the dataset? If so, please describe how.*
	- It would be possible to identify individuals from the dataset if there were enough information in their account details and their message, as this data is included and gathered alongside the tweet instance.
15. *Does the dataset contain data that might be considered sensitive in any way (for example, data that reveals race or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)? If so, please provide a description.*
	- The data contains the geographical location of where the tweet was sent and the geographical location of the user. There is no other sensitive information included.
16. *Any other comments?*
	- None

**Collection process**

1. *How was the data associated with each instance acquired? Was the data directly observable (for example, raw text, movie ratings), reported by subjects (for example, survey responses), or indirectly inferred/derived from other data (for example, part-of-speech tags, model-based guesses for age or language)? If the data was reported by subjects or indirectly inferred/derived from other data, was the data validated/verified? If so, please describe how.*
	- The data was directly observable from each tweet and user, as tweets are sent as raw text and other details are directly obtainible from the timestamp and self-provided user information. 
2. *What mechanisms or procedures were used to collect the data (for example, hardware apparatuses or sensors, manual human curation, software programs, software APIs)? How were these mechanisms or procedures validated?*
	- The data was collected using the rtweet package found in R. These procedures were validated by manually checking that the program was gathering valid tweets using the status id and referencing of tweets and accounts. 
3. *If the dataset is a sample from a larger set, what was the sampling strategy (for example, deterministic, probabilistic with specific sampling probabilities)?*
	- The sampling strategy was to take recent tweets matching the search criteria as of the time of request. Recent tweets are shown in order of time posted.
4. *Who was involved in the data collection process (for example, students, crowdworkers, contractors) and how were they compensated (for example, how much were crowdworkers paid)?*
	- Only the author of the paper was involved in data collection.
5. *Over what timeframe was the data collected? Does this timeframe match the creation timeframe of the data associated with the instances (for example, recent crawl of old news articles)? If not, please describe the timeframe in which the data associated with the instances was created.*
	- The data was collected over two timeframes- on April 10 and on April 23 2022. The timeframe roughly matches the creation timeframe of the data: The creation timeframes are roughly from April 4-10 and April 17-23 2022. These times are when daily tweets are collected.
6. *Were any ethical review processes conducted (for example, by an institutional review board)? If so, please provide a description of these review processes, including the outcomes, as well as a link or other access point to any supporting documentation.*
	- None
7. *Did you collect the data from the individuals in question directly, or obtain it via third parties or other sources (for example, websites)?*
	- The data was collected from other sources, using the rtweet package.
8. *Were the individuals in question notified about the data collection? If so, please describe (or show with screenshots or other information) how notice was provided, and provide a link or other access point to, or otherwise reproduce, the exact language of the notification itself.*
	- The individuals in question were not notified about the data collection.
9. *Did the individuals in question consent to the collection and use of their data? If so, please describe (or show with screenshots or other information) how consent was requested and provided, and provide a link or other access point to, or otherwise reproduce, the exact language to which the individuals consented.*
	- The individuals in question consented to the collection and use of their data in the Twitter Terms of Service which all users must agree to for site access. The link can be found here: https://twitter.com/en/tos
	
10. *If consent was obtained, were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses? If so, please provide a description, as well as a link or other access point to the mechanism (if appropriate).*
	- Consenting individuals may choose to deactivate their account which would delete all messages and tweets they had sent from the platform.
11. *Has an analysis of the potential impact of the dataset and its use on data subjects (for example, a data protection impact analysis) been conducted? If so, please provide a description of this analysis, including the outcomes, as well as a link or other access point to any supporting documentation.*
	- None
12. *Any other comments?*
	- None

**Preprocessing/cleaning/labeling**

1. *Was any preprocessing/cleaning/labeling of the data done (for example, discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)? If so, please provide a description. If not, you may skip the remaining questions in this section.*
	- Cleaning of the data was done to obtain more relevance in our dataset. After the raw data was collected, observations were filtered by specific message criteria. The relevant data (Wordle scores) are contained in messages through specific phrases which are copied and pasted by users from the game's website. Scores take the form of the phrase "Wordle ___ _/6" where the number of the daily word and the number of guesses taken by the player are displayed. Tweets were filtered according to whether this phrase was included in their tweet. Once this was done, the numerical data of the number of guesses the user took was extracted from the message text and stored as a new variable. Games in which the user did not successfully guess the word in 6 tries, and therefore failed, were counted as taking 7 guesses to complete. After this was done, the date and time that the tweets were sent was extracted from the Unix time provided in the raw data using the lubridate [@citelubridate] package. A binary variable was also created indicating if the user had 'hard mode' enabled in their game, which adds additional conditions to the game making it more challenging. This indication was availible in the raw text; messages from hard mode players would contain a  "_/6*" in their tweet, the star indicating the use of hard mode. Once this was done, the data was aggregated into a single dataframe. Partitions were also made according to the creation timeframe of the tweets for potential future use.
	
2. *Was the "raw" data saved in addition to the preprocessed/cleaned/labeled data (for example, to support unanticipated future uses)? If so, please provide a link or other access point to the "raw" data.*
	- The "raw" data is contained in the repository that this paper is contained in.
3. *Is the software that was used to preprocess/clean/label the data available? If so, please provide a link or other access point.*
	- The software used to clean the data consists of R packages, which have been cited and credited.
4. *Any other comments?*
	- None

**Uses**

1. *Has the dataset been used for any tasks already? If so, please provide a description.*
	- None
2. *Is there a repository that links to any or all papers or systems that use the dataset? If so, please provide a link or other access point.*
	- Yes. Code and data are available at: https://github.com/Ivannoar/Twilight
3. *What (other) tasks could the dataset be used for?*
	- Other tasks might consist of more analysis pertaining to Wordle, as well as using the dataset to draw conclusions based on Twitter in general.
4. *Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? For example, is there anything that a dataset consumer might need to know to avoid uses that could result in unfair treatment of individuals or groups (for example, stereotyping, quality of service issues) or other risks or harms (for example, legal risks, financial harms)? If so, please provide a description. Is there anything a dataset consumer could do to mitigate these risks or harms?*
	- Tweet geographical and chronological data, as well as the status and description of the accounts used could be used to unfairly treat the individuals involved. A dataset consumer might avoid making these conclusions and taking the data at more of face value.
5. *Are there tasks for which the dataset should not be used? If so, please provide a description.*
	- The dataset should not be used for any malicious or illegal activity.
6. *Any other comments?*
	- None

**Distribution**

1. *Will the dataset be distributed to third parties outside of the entity (for example, company, institution, organization) on behalf of which the dataset was created? If so, please provide a description.*
	- The dataset will not be explicitly distributed to third parties, but will be made availible publically online.
2. *How will the dataset be distributed (for example, tarball on website, API, GitHub)? Does the dataset have a digital object identifier (DOI)?*
	- The dataset will be distributed on GitHub via this paper's repository.
3. *When will the dataset be distributed?*
	- The dataset will be distributed on April 27, 2022.
4. *Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)? If so, please describe this license and/ or ToU, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms or ToU, as well as any fees associated with these restrictions.*
	- None
5. *Have any third parties imposed IP-based or other restrictions on the data associated with the instances? If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any relevant licensing terms, as well as any fees associated with these restrictions.*
	- None
6. *Do any export controls or other regulatory restrictions apply to the dataset or to individual instances? If so, please describe these restrictions, and provide a link or other access point to, or otherwise reproduce, any supporting documentation.*
	- None
7. *Any other comments?*
	- None

**Maintenance**

1. *Who will be supporting/hosting/maintaining the dataset?*
	- The dataset will be hosted by the author of the paper.
2. *How can the owner/curator/manager of the dataset be contacted (for example, email address)?*
	- The owner of the dataset can be reached via the GitHub account the repository is hosted on.
3. *Is there an erratum? If so, please provide a link or other access point.*
	- None
4. *Will the dataset be updated (for example, to correct labeling errors, add new instances, delete instances)? If so, please describe how often, by whom, and how updates will be communicated to dataset consumers (for example, mailing list, GitHub)?*
	- The dataset will not be updated.
5. *If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (for example, were the individuals in question told that their data would be retained for a fixed period of time and then deleted)? If so, please describe these limits and explain how they will be enforced.*
	- There are no limits on the retention of the data associated with the instances.
6. *Will older versions of the dataset continue to be supported/hosted/maintained? If so, please describe how. If not, please describe how its obsolescence will be communicated to dataset consumers.*
	- Older versions of the dataset may be hosted by the author of the paper on their local files. The obsolescence will be communicated from the repository the paper is hosted on.
7. *If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so? If so, please provide a description. Will these contributions be validated/verified? If so, please describe how. If not, why not? Is there a process for communicating/distributing these contributions to dataset consumers? If so, please provide a description.*
	- Others can contribute to the dataset via GitHub's built-in collaboration features, which will be verified and finalized by the author.
8. *Any other comments?*
	- None


\newpage

# References